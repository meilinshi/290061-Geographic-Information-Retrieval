{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35e49539-abae-46dc-a22d-171f444473d1",
   "metadata": {},
   "source": [
    "# Lab 5 - Spatial Indexing\n",
    "\n",
    "Th. 7.11.2024 15:00-17:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf0b977-c131-41f3-98d3-4b8facfabd50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "## 1 Installation of BeautifulSoup\n",
    "\n",
    "[Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/) is a library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser, providing Pythonic idioms for iterating, searching, and modifying the parse tree.\n",
    "\n",
    "![bs4](../figs/lab5_figs/bs4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79375df7-b03b-4201-a28c-2aa1c2c2c8b7",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 Inverted Indexing\n",
    "\n",
    "In this section we will first create an inverted index and then query with the created index. In order to achieve the first step, we will first retrieve data from Wikipedia about 5 cities/towns in Austria. Here we will also need to retrieve their point <strong>coordinates</strong> for later spatial indexing.\n",
    "\n",
    "### 2.1 Create an Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb4b3ed-0e56-46bd-b558-0859f053b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia ## for getting Wikipedia summaries\n",
    "\n",
    "## while during installation the package name is BeautifulSoup4,\n",
    "## here it is still called BeautifulSoup when being imported\n",
    "from bs4 import BeautifulSoup \n",
    "import requests ## used along with BeautifulSoup\n",
    "\n",
    "from geopy.geocoders import ArcGIS ## for geocoding city/town names\n",
    "\n",
    "import spacy ## for text processing\n",
    "import geopandas as gpd ## for spatial indexing\n",
    "\n",
    "## for the later query with spatial indexing \n",
    "from shapely.geometry import Point, box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56743d4-f895-419d-82bf-f419e286df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_list = ['Vienna','Salzburg','Linz','Innsbruck','Hallstatt']\n",
    "\n",
    "poi_wikipedia_list = []\n",
    "for poi in poi_list:\n",
    "    summary = wikipedia.summary(poi + ', Austria') ## adding Austria in the search will help return more accurate results\n",
    "    summary = summary.replace('\\n','')\n",
    "    url = \"https://en.wikipedia.org/wiki/\" + poi\n",
    "    req = requests.get(url).text\n",
    "    soup = BeautifulSoup(req)\n",
    "    latitude = soup.find(\"span\", {\"class\": \"latitude\"})\n",
    "    longitude = soup.find(\"span\", {\"class\": \"longitude\"})\n",
    "    poi_wikipedia_list.append({'summary': summary, 'latitude': latitude.text, 'longitude': longitude.text})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e46376-04c5-40ee-9f5f-54f1d14130bb",
   "metadata": {},
   "source": [
    "In the code block above, what BeautifulSoup is looking for the element that has a `<span>` tag and a `latitude` or `longitude` class in an HTML webpage. Below is an example of Salzburg's Wikipedia webpage.\n",
    "\n",
    "![wiki_coord_inspect](../figs/lab5_figs/wiki_coord_inspect.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ecc28-9a19-4a43-a4de-eb7e20405e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") ## load an English trained pipeline\n",
    "\n",
    "## use a set instead of a list to store tokens from a document collection\n",
    "## a set makes sure there is no duplicate elements\n",
    "token_set = set() \n",
    "\n",
    "## use the built-in enumerate() function to get the counter and the item when iterating a list\n",
    "for index, item in enumerate(poi_wikipedia_list): \n",
    "    summary = item['summary']\n",
    "\n",
    "    ## get only the lowercase token after lemmatization (https://spacy.io/usage/linguistic-features#lemmatization)\n",
    "    ## stop words are not considered during this process (https://en.wikipedia.org/wiki/Stop_word)\n",
    "    ## and only tokens containing alphabetic characters are included (https://spacy.io/api/token)\n",
    "    tokens =  [token.lemma_.lower() for token in nlp(summary) if token.lemma_.lower() not in nlp.Defaults.stop_words and token.is_alpha]\n",
    "    poi_wikipedia_list[index]['tokens'] = tokens\n",
    "    \n",
    "    token_set = token_set.union(set(tokens)) ## use the union method to merge two sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f424bd3-630c-4201-94d4-d5bb1df35f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(token_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e515c-534e-46a0-8441-e19c587852a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## inverted_index is a dictionary\n",
    "## each key-value pair in inverted_index is a term and its corresponding list of document ids\n",
    "\n",
    "inverted_index = {}\n",
    "for token in token_set:\n",
    "    inverted_index[token] = []\n",
    "    for index, item in enumerate(poi_wikipedia_list):\n",
    "        if token in item['tokens']:\n",
    "            inverted_index[token].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e847b68-0eaa-498b-a978-77ce9ea9fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inverted_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee8e768-48e7-4904-a6a7-1e908516de83",
   "metadata": {},
   "source": [
    "### 2.2 Query with Inverted Indexing\n",
    "Next we are going to use a query to search for relevant documents. The example query is <strong>cities associated with Alps</strong>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f9824-41df-4d69-8543-eeea7cce9aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'cities associated with Alps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a54f80-b1bb-4cfa-99a6-08d821a297c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_index_set = set()\n",
    "\n",
    "for index, token in enumerate(nlp(query)):\n",
    "    if token.lemma_.lower() not in nlp.Defaults.stop_words and token.is_alpha:\n",
    "        ## use the try and except blocks to handle errors such as KeyError\n",
    "        ## KeyError will happen if a token in the query does not exist in the keys of the inverted index\n",
    "        ## https://www.w3schools.com/python/python_try_except.asp\n",
    "        try:\n",
    "            print('The token \\'', token, '\\' appears in ', set(inverted_index[token.lemma_.lower()]))\n",
    "            if index == 0:\n",
    "                ## use the union method to populate the set at the beginning\n",
    "                result_index_set = result_index_set.union(set(inverted_index[token.lemma_.lower()]))\n",
    "            else:\n",
    "                ## use the intersection method to find out overlaps between the set and a new set\n",
    "                ## the new set is the associated list of document ids with the next token (in the query)\n",
    "                result_index_set = result_index_set.intersection(set(inverted_index[token.lemma_.lower()]))\n",
    "        except KeyError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafb838c-cab3-41df-bdc2-b3ba0a76248d",
   "metadata": {},
   "source": [
    "The returned set of document ids by the given query is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ae06d-cdda-4e70-a953-7ab6fca0eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_index_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a914bbf1-ff55-47b3-b711-0cb739b08efb",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 Spatial Indexing\n",
    "\n",
    "For spatial indexing, we will rely on the built-in <a href='https://geopandas.org/en/stable/docs/reference/sindex.html'>STRtree implementation of GeoPandas</a>.\n",
    "\n",
    "![rtree_gpd](../figs/lab5_figs/rtree_gpd.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3554f96b-fd37-4d64-8301-f386102647cc",
   "metadata": {},
   "source": [
    "### 3.1 Create a Spatial Index\n",
    "To create a spatial index, we need to use the coordinates retrieved before. We also need to convert these coordinates into decimal degrees, and then create a GeoDataFrame that includes city names, summaries, and geometries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcc7eb4-f5de-4104-9f94-96b0df010c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2decimal(num, islatorlon): ## a function for converting coordinates into decimal degrees\n",
    "    num = num.replace('°',',')\n",
    "    num = num.replace('′',',')\n",
    "    num = num.replace('″',',')\n",
    "    num = num.split(',')\n",
    "    decimal = float(num[0]) + float(num[1])/60 + float(num[2])/3600\n",
    "    if islatorlon == 'lat':\n",
    "        if num[3] == 'S': ## include a minus sign for locations in the southern hemisphere\n",
    "            return -decimal\n",
    "        else:\n",
    "            return decimal\n",
    "    else:\n",
    "        if num[3] == 'W': ## include a minus sign for locations to the west of the prime meridian\n",
    "            return -decimal\n",
    "        else:\n",
    "            return decimal\n",
    "\n",
    "## a dictionary for storing relevant city information\n",
    "poi_wikipedia_dict = {'name':[],'summary':[],'geometry':[]}\n",
    "\n",
    "for i in range(len(poi_list)):\n",
    "    poi_wikipedia_dict['name'].append(poi_list[i])\n",
    "    poi_wikipedia_dict['summary'].append(poi_wikipedia_list[i]['summary'])\n",
    "    lat = poi_wikipedia_list[i]['latitude']\n",
    "    lon = poi_wikipedia_list[i]['longitude']\n",
    "    lat = convert2decimal(lat,'lat')\n",
    "    lon = convert2decimal(lon,'lon')\n",
    "    poi_wikipedia_dict['geometry'].append(Point(lon, lat)) ## create a Point object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2db75a-5fb7-4116-9fc7-a1f9e8088960",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a GeoDataFrame from the dictionary\n",
    "## make sure to set the crs (coordinate reference system)\n",
    "df_poi_wikipedia = gpd.GeoDataFrame(data = poi_wikipedia_dict, columns = ['name', 'summary','geometry'], crs = 'EPSG:4326')\n",
    "df_poi_wikipedia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fd6cde-79bf-4e84-af8b-8cd9d3f27157",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the spatial index\n",
    "spatial_index = df_poi_wikipedia.sindex\n",
    "spatial_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673025a-f233-491a-b37f-a9b0cfb7fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_index.size ## check the size of the spatial index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d900cc1-b8a0-4c93-9869-e4a4f17b670d",
   "metadata": {},
   "source": [
    "### 3.2 Query with Spatial Indexing\n",
    "Here we will use five close-by cities to generate queries about them in relation to the created spatial index. To do so, we need to first geocode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c98595-1ccc-4aef-ac7c-d80f244e5e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_locations = ['Graz','Prague','Budapest','Munich','Zurich']\n",
    "\n",
    "geolocator_arcgis = ArcGIS()\n",
    "\n",
    "query_lon_list = []\n",
    "query_lat_list = []\n",
    "for address in query_locations:\n",
    "    location = geolocator_arcgis.geocode(address)\n",
    "    query_lon_list.append(location.longitude)\n",
    "    query_lat_list.append(location.latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e43c85-3dcc-4b60-a975-0d22f3986cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we will generate a GeoSeries from their coordinates\n",
    "query_geoseries = gpd.GeoSeries(gpd.points_from_xy(query_lon_list, query_lat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89f42c-ab25-42d3-a53e-8cc25d755065",
   "metadata": {},
   "outputs": [],
   "source": [
    "## not only we can find the nearest city to a random Point...\n",
    "spatial_index.nearest(Point(14.5501, 47.5162))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f16cd2-12db-4498-8bca-bc836d6c4ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## but also we can find the nearest city of a list of Points in the created GeoSeries\n",
    "spatial_index.nearest(query_geoseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ad2fd-9f27-4e59-9635-a989903e3012",
   "metadata": {},
   "source": [
    "In the output above, the first subarray of indices contains input geometry indices. The second subarray of indices contains tree geometry indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a1b2e-84a1-4860-81d7-9c058b94e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can also create a bounding box to find out what cities are within it\n",
    "spatial_index.query(box(9.47996951665, 46.4318173285, 16.9796667823, 49.0390742051))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d99d0-a8fc-4d7c-9fcf-46d1d62108e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_index.valid_query_predicates ## check the valid query predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400979a0-fd3c-43f4-9c8e-e5f077eab389",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the 'contains' predicate with return all cities\n",
    "spatial_index.query(box(9.47996951665, 46.4318173285, 16.9796667823, 49.0390742051), predicate = 'contains')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecdea5a-e832-4302-8c69-0cefcf576b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the 'within' predicate with return none\n",
    "spatial_index.query(box(9.47996951665, 46.4318173285, 16.9796667823, 49.0390742051), predicate = 'within')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090c7b1f-aa46-4aaa-9b14-72189ea89ff3",
   "metadata": {},
   "source": [
    "In addition to 'contains', other predicates can be chosen depending on the geometries of indexed and queried objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c014292c-684d-4c2c-b6a7-f62ab887402e",
   "metadata": {},
   "source": [
    "---\n",
    "## Submission\n",
    "Run the codes above and submit the .ipynb file along with answers to the following questions:\n",
    "- Based on the indices returned by ```result_index_set```, what are the cities 'associated with Alps'?\n",
    "- Try to use a different query with inverted indexing, what are the indices returned? Do the results make sense?\n",
    "- Based on the index pairs returned by ```spatial_index.nearest(query_geoseries)```, for each city in ```query_locations``` what is its nearest city in ```poi_list```?\n",
    "- Try to use a different bounding box for ```spatial_index.query()```, what are the cities that will be returned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ae014-abee-41b0-af12-b1b6d2741326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
