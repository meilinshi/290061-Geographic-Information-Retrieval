{
 "cells": [
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "35e49539-abae-46dc-a22d-171f444473d1",
   "metadata": {},
   "source": [
    "# Lab 5 - Spatial Indexing\n",
    "\n",
    "Th. 7.11.2024 15:00-17:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf0b977-c131-41f3-98d3-4b8facfabd50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "## 1 Installation of BeautifulSoup\n",
    "\n",
    "[Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/) is a library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser, providing Pythonic idioms for iterating, searching, and modifying the parse tree.\n",
    "\n",
    "![bs4](../figs/lab5_figs/bs4.png)"
=======
   "id": "00532ba9-c0d4-4bfe-beea-a0559aa0c747",
   "metadata": {
    "id": "00532ba9-c0d4-4bfe-beea-a0559aa0c747"
   },
   "source": [
    "# Lab 5 - Geocoding\n",
    "\n",
    "Th 31.10.2024 15:00-17:00\n",
    "***"
>>>>>>> 444a0eec4505859ac59db5a7830d198c1a05cf9a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "79375df7-b03b-4201-a28c-2aa1c2c2c8b7",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 Inverted Indexing\n",
    "\n",
    "In this section we will first create an inverted index and then query with the created index. In order to achieve the first step, we will first retrieve data from Wikipedia about 5 cities/towns in Austria. Here we will also need to retrieve their point <strong>coordinates</strong> for later spatial indexing.\n",
    "\n",
    "### 2.1 Create an Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb4b3ed-0e56-46bd-b558-0859f053b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia ## for getting Wikipedia summaries\n",
    "\n",
    "## while during installation the package name is BeautifulSoup4,\n",
    "## here it is still called BeautifulSoup when being imported\n",
    "from bs4 import BeautifulSoup \n",
    "import requests ## used along with BeautifulSoup\n",
    "\n",
    "from geopy.geocoders import ArcGIS ## for geocoding city/town names\n",
    "\n",
    "import spacy ## for text processing\n",
    "import geopandas as gpd ## for spatial indexing\n",
    "\n",
    "## for the later query with spatial indexing \n",
    "from shapely.geometry import Point, box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56743d4-f895-419d-82bf-f419e286df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_list = ['Vienna','Salzburg','Linz','Innsbruck','Hallstatt']\n",
    "\n",
    "poi_wikipedia_list = []\n",
    "for poi in poi_list:\n",
    "    summary = wikipedia.summary(poi + ', Austria') ## adding Austria in the search will help return more accurate results\n",
    "    summary = summary.replace('\\n','')\n",
    "    url = \"https://en.wikipedia.org/wiki/\" + poi\n",
    "    req = requests.get(url).text\n",
    "    soup = BeautifulSoup(req)\n",
    "    latitude = soup.find(\"span\", {\"class\": \"latitude\"})\n",
    "    longitude = soup.find(\"span\", {\"class\": \"longitude\"})\n",
    "    poi_wikipedia_list.append({'summary': summary, 'latitude': latitude.text, 'longitude': longitude.text})"
=======
   "id": "780edf8e",
   "metadata": {},
   "source": [
    "## 1 - Geopy\n",
    "\n",
    "[Geopy](https://geopy.readthedocs.io/en/stable/) is a Python library that provides a simple interface for several geocoding web services. \n",
    "\n",
    "\n",
    "![geopy](../figs/lab5_figs/geopy.png)"
>>>>>>> 444a0eec4505859ac59db5a7830d198c1a05cf9a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "24e46376-04c5-40ee-9f5f-54f1d14130bb",
   "metadata": {},
   "source": [
    "In the code block above, what BeautifulSoup is looking for the element that has a `<span>` tag and a `latitude` or `longitude` class in an HTML webpage. Below is an example of Salzburg's Wikipedia webpage.\n",
    "\n",
    "![wiki_coord_inspect](../figs/lab5_figs/wiki_coord_inspect.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ecc28-9a19-4a43-a4de-eb7e20405e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") ## load an English trained pipeline\n",
    "\n",
    "## use a set instead of a list to store tokens from a document collection\n",
    "## a set makes sure there is no duplicate elements\n",
    "token_set = set() \n",
    "\n",
    "## use the built-in enumerate() function to get the counter and the item when iterating a list\n",
    "for index, item in enumerate(poi_wikipedia_list): \n",
    "    summary = item['summary']\n",
    "\n",
    "    ## get only the lowercase token after lemmatization (https://spacy.io/usage/linguistic-features#lemmatization)\n",
    "    ## stop words are not considered during this process (https://en.wikipedia.org/wiki/Stop_word)\n",
    "    ## and only tokens containing alphabetic characters are included (https://spacy.io/api/token)\n",
    "    tokens =  [token.lemma_.lower() for token in nlp(summary) if token.lemma_.lower() not in nlp.Defaults.stop_words and token.is_alpha]\n",
    "    poi_wikipedia_list[index]['tokens'] = tokens\n",
    "    \n",
    "    token_set = token_set.union(set(tokens)) ## use the union method to merge two sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f424bd3-630c-4201-94d4-d5bb1df35f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(token_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e515c-534e-46a0-8441-e19c587852a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## inverted_index is a dictionary\n",
    "## each key-value pair in inverted_index is a term and its corresponding list of document ids\n",
    "\n",
    "inverted_index = {}\n",
    "for token in token_set:\n",
    "    inverted_index[token] = []\n",
    "    for index, item in enumerate(poi_wikipedia_list):\n",
    "        if token in item['tokens']:\n",
    "            inverted_index[token].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e847b68-0eaa-498b-a978-77ce9ea9fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inverted_index)"
=======
   "id": "ebff1f55",
   "metadata": {},
   "source": [
    "### 1.1 - Choose a Geocoding Service\n",
    "Geopy supports various geocoding services, such as Google Maps, OpenStreetMap, and ArcGIS. Each service may have different usage policies and limitations. For example, some may require **API keys**. Geopy implemented the class for each of these services, and you can easily switch from one serviceâ€™s API to another."
>>>>>>> 444a0eec4505859ac59db5a7830d198c1a05cf9a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "fee8e768-48e7-4904-a6a7-1e908516de83",
   "metadata": {},
   "source": [
    "### 2.2 Query with Inverted Indexing\n",
    "Next we are going to use a query to search for relevant documents. The example query is <strong>cities associated with Alps</strong>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f9824-41df-4d69-8543-eeea7cce9aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'cities associated with Alps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a54f80-b1bb-4cfa-99a6-08d821a297c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_index_set = set()\n",
    "\n",
    "for index, token in enumerate(nlp(query)):\n",
    "    if token.lemma_.lower() not in nlp.Defaults.stop_words and token.is_alpha:\n",
    "        ## use the try and except blocks to handle errors such as KeyError\n",
    "        ## KeyError will happen if a token in the query does not exist in the keys of the inverted index\n",
    "        ## https://www.w3schools.com/python/python_try_except.asp\n",
    "        try:\n",
    "            print('The token \\'', token, '\\' appears in ', set(inverted_index[token.lemma_.lower()]))\n",
    "            if index == 0:\n",
    "                ## use the union method to populate the set at the beginning\n",
    "                result_index_set = result_index_set.union(set(inverted_index[token.lemma_.lower()]))\n",
    "            else:\n",
    "                ## use the intersection method to find out overlaps between the set and a new set\n",
    "                ## the new set is the associated list of document ids with the next token (in the query)\n",
    "                result_index_set = result_index_set.intersection(set(inverted_index[token.lemma_.lower()]))\n",
    "        except KeyError:\n",
    "            continue"
=======
   "id": "12effd0f",
   "metadata": {},
   "source": [
    "### 1.2 - Import and Choose a Geocoder:\n",
    "Import the geopy library and choose a geocoding service. For example, if you want to use the Nominatim geocoding service (which is based on **OpenStreetMap** data), you can do the following:<br>\n",
    "`from geopy.geocoders import Nominatim` <br>\n",
    "`geolocator = Nominatim(user_agent=\"your_email\")`\n",
    "\n",
    "If you want to use the **Google Maps** geocoding service, you can do the following:<br>\n",
    "`GM_API_KEY = 'your_api_key'`<br>\n",
    "`from geopy.geocoders import GoogleV3` <br>\n",
    "`geolocator = GoogleV3(api_key=GM_API_KEY)`\n",
    "\n",
    "If you want to use the **ArcGIS** geocoding service, you can do the following:<br>\n",
    "`from geopy.geocoders import ArcGIS` <br>\n",
    "`geolocator = ArcGIS()`"
>>>>>>> 444a0eec4505859ac59db5a7830d198c1a05cf9a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "eafb838c-cab3-41df-bdc2-b3ba0a76248d",
   "metadata": {},
   "source": [
    "The returned set of document ids by the given query is as follows."
=======
   "id": "8b8c3b72",
   "metadata": {},
   "source": [
    "### 1.3 - Geocode a single address"
>>>>>>> 444a0eec4505859ac59db5a7830d198c1a05cf9a
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "ef6ae06d-cdda-4e70-a953-7ab6fca0eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_index_set"
=======
   "id": "dc7e9d76-705c-4aca-9a1c-59f5ce10bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "address='UniversitÃ¤tsstraÃŸe 7, 1010 Wien'"
>>>>>>> 444a0eec4505859ac59db5a7830d198c1a05cf9a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "a914bbf1-ff55-47b3-b711-0cb739b08efb",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 Spatial Indexing\n",
    "\n",
    "For spatial indexing, we will rely on the built-in <a href='https://geopandas.org/en/stable/docs/reference/sindex.html'>STRtree implementation of GeoPandas</a>.\n",
    "\n",
    "![rtree_gpd](../figs/lab5_figs/rtree_gpd.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3554f96b-fd37-4d64-8301-f386102647cc",
   "metadata": {},
   "source": [
    "### 3.1 Create a Spatial Index\n",
    "To create a spatial index, we need to use the coordinates retrieved before. We also need to convert these coordinates into decimal degrees, and then create a GeoDataFrame that includes city names, summaries, and geometries."
=======
   "id": "38ddf165",
   "metadata": {},
   "source": [
    "**ArcGIS:**"
>>>>>>> 444a0eec4505859ac59db5a7830d198c1a05cf9a
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "edcc7eb4-f5de-4104-9f94-96b0df010c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2decimal(num, islatorlon): ## a function for converting coordinates into decimal degrees\n",
    "    num = num.replace('Â°',',')\n",
    "    num = num.replace('â€²',',')\n",
    "    num = num.replace('â€³',',')\n",
    "    num = num.split(',')\n",
    "    decimal = float(num[0]) + float(num[1])/60 + float(num[2])/3600\n",
    "    if islatorlon == 'lat':\n",
    "        if num[3] == 'S': ## include a minus sign for locations in the southern hemisphere\n",
    "            return -decimal\n",
    "        else:\n",
    "            return decimal\n",
    "    else:\n",
    "        if num[3] == 'W': ## include a minus sign for locations to the west of the prime meridian\n",
    "            return -decimal\n",
    "        else:\n",
    "            return decimal\n",
    "\n",
    "## a dictionary for storing relevant city information\n",
    "poi_wikipedia_dict = {'name':[],'summary':[],'geometry':[]}\n",
    "\n",
    "for i in range(len(poi_list)):\n",
    "    poi_wikipedia_dict['name'].append(poi_list[i])\n",
    "    poi_wikipedia_dict['summary'].append(poi_wikipedia_list[i]['summary'])\n",
    "    lat = poi_wikipedia_list[i]['latitude']\n",
    "    lon = poi_wikipedia_list[i]['longitude']\n",
    "    lat = convert2decimal(lat,'lat')\n",
    "    lon = convert2decimal(lon,'lon')\n",
    "    poi_wikipedia_dict['geometry'].append(Point(lon, lat)) ## create a Point object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2db75a-5fb7-4116-9fc7-a1f9e8088960",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a GeoDataFrame from the dictionary\n",
    "## make sure to set the crs (coordinate reference system)\n",
    "df_poi_wikipedia = gpd.GeoDataFrame(data = poi_wikipedia_dict, columns = ['name', 'summary','geometry'], crs = 'EPSG:4326')\n",
    "df_poi_wikipedia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fd6cde-79bf-4e84-af8b-8cd9d3f27157",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the spatial index\n",
    "spatial_index = df_poi_wikipedia.sindex\n",
    "spatial_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673025a-f233-491a-b37f-a9b0cfb7fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_index.size ## check the size of the spatial index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d900cc1-b8a0-4c93-9869-e4a4f17b670d",
   "metadata": {},
   "source": [
    "### 3.2 Query with Spatial Indexing\n",
    "Here we will use five close-by cities to generate queries about them in relation to the created spatial index. To do so, we need to first geocode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c98595-1ccc-4aef-ac7c-d80f244e5e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_locations = ['Graz','Prague','Budapest','Munich','Zurich']\n",
    "\n",
    "geolocator_arcgis = ArcGIS()\n",
    "\n",
    "query_lon_list = []\n",
    "query_lat_list = []\n",
    "for address in query_locations:\n",
    "    location = geolocator_arcgis.geocode(address)\n",
    "    query_lon_list.append(location.longitude)\n",
    "    query_lat_list.append(location.latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e43c85-3dcc-4b60-a975-0d22f3986cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we will generate a GeoSeries from their coordinates\n",
    "query_geoseries = gpd.GeoSeries(gpd.points_from_xy(query_lon_list, query_lat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89f42c-ab25-42d3-a53e-8cc25d755065",
   "metadata": {},
   "outputs": [],
   "source": [
    "## not only we can find the nearest city to a random Point...\n",
    "spatial_index.nearest(Point(14.5501, 47.5162))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f16cd2-12db-4498-8bca-bc836d6c4ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## but also we can find the nearest city of a list of Points in the created GeoSeries\n",
    "spatial_index.nearest(query_geoseries)"
=======
   "id": "57538efc-33a9-4d67-a0ce-7fdd5f6db88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import ArcGIS\n",
    "geolocator_arcgis = ArcGIS()\n",
    "\n",
    "location = geolocator_arcgis.geocode(address)\n",
    "print((location.latitude, location.longitude))"
>>>>>>> 444a0eec4505859ac59db5a7830d198c1a05cf9a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "2d2ad2fd-9f27-4e59-9635-a989903e3012",
   "metadata": {},
   "source": [
    "In the output above, the first subarray of indices contains input geometry indices. The second subarray of indices contains tree geometry indices."
=======
   "id": "ccd384cc",
   "metadata": {},
   "source": [
    "**OpenStreetMap:**\n",
    "\n",
    "OpenStreetMap's API is free of charge. You will need to give the email of your OSM account as input to the Nominatim class, instead of the API key."
>>>>>>> 444a0eec4505859ac59db5a7830d198c1a05cf9a
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "ee1a1b2e-84a1-4860-81d7-9c058b94e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can also create a bounding box to find out what cities are within it\n",
    "spatial_index.query(box(9.47996951665, 46.4318173285, 16.9796667823, 49.0390742051))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d99d0-a8fc-4d7c-9fcf-46d1d62108e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_index.valid_query_predicates ## check the valid query predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400979a0-fd3c-43f4-9c8e-e5f077eab389",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the 'contains' predicate with return all cities\n",
    "spatial_index.query(box(9.47996951665, 46.4318173285, 16.9796667823, 49.0390742051), predicate = 'contains')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecdea5a-e832-4302-8c69-0cefcf576b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the 'within' predicate with return none\n",
    "spatial_index.query(box(9.47996951665, 46.4318173285, 16.9796667823, 49.0390742051), predicate = 'within')"
=======
   "id": "1a02edba-ddb6-4bcd-8fdf-6fd5447d2818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "## Set a higher timeout value (in seconds)\n",
    "geolocator_osm = Nominatim(user_agent=\"xxxxx@gmail.com\",timeout=10)\n",
    "\n",
    "location = geolocator_osm.geocode(address)\n",
    "print((location.latitude, location.longitude))"
>>>>>>> 444a0eec4505859ac59db5a7830d198c1a05cf9a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "090c7b1f-aa46-4aaa-9b14-72189ea89ff3",
   "metadata": {},
   "source": [
    "In addition to 'contains', other predicates can be chosen depending on the geometries of indexed and queried objects."
=======
   "id": "cee33829",
   "metadata": {},
   "source": [
    "**Google Maps:**\n",
    "\n",
    "Google Maps API includes more steps including setting up a billing account, so we are skipping this in class. More info [here](https://developers.google.com/maps/documentation/geocoding/cloud-setup).\n",
    "\n",
    "![gm](../figs/lab5_figs/gm.png)"
>>>>>>> 444a0eec4505859ac59db5a7830d198c1a05cf9a
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "c014292c-684d-4c2c-b6a7-f62ab887402e",
   "metadata": {},
   "source": [
    "---\n",
    "## Submission\n",
    "Run the codes above and submit the .ipynb file along with answers to the following questions:\n",
    "- Based on the indices returned by ```result_index_set```, what are the cities 'associated with Alps'?\n",
    "- Try to use a different query with inverted indexing, what are the indices returned? Do the results make sense?\n",
    "- Based on the index pairs returned by ```spatial_index.nearest(query_geoseries)```, for each city in ```query_locations``` what is its nearest city in ```poi_list```?\n",
    "- Try to use a different bounding box for ```spatial_index.query()```, what are the cities that will be returned?"
=======
   "id": "d975c7b4",
   "metadata": {},
   "source": [
    "### 1.4 - Geocode a list of addresses and handle errors"
>>>>>>> 444a0eec4505859ac59db5a7830d198c1a05cf9a
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "aa0ae014-abee-41b0-af12-b1b6d2741326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
=======
   "id": "2e46e096-54b3-425e-adb9-8aa88ef78b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## this csv includes top 30 cafes in Vienna \n",
    "## based on TripAdvisor ratings and number of reviews\n",
    "## lat and lon columns are geocoded using Google Maps API\n",
    "## with additional manual inspection, can be seen as ground truth\n",
    "df = pd.read_csv('cafe_poi_30.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a7b8d-ca73-4896-8861-5a164f7b4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def service_geocode(g_locator, address):\n",
    "    location = g_locator.geocode(address)\n",
    "    if location!= None:\n",
    "        return (location.latitude, location.longitude)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a38c0-3c5e-49bc-b34e-12b83666af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## arcgis:\n",
    "df['LAT_LON_arcgis'] = df['name'].apply(lambda x: service_geocode(geolocator_arcgis, (x+', Vienna')))\n",
    "\n",
    "## OpenStreetMap:\n",
    "df['LAT_LON_osm'] = df['name'].apply(lambda x: service_geocode(geolocator_osm,(x+', Vienna')))\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3736803",
   "metadata": {},
   "source": [
    "## 2 - Evaluation\n",
    "\n",
    "### 2.1 - Ground Truth Comparison\n",
    "Consider the `lat` `lon` columns in the dataframe as ground truth and compare the geocoding results against it.\n",
    "\n",
    "### 2.2 - Error Metrics \n",
    "We can use metrics like: \n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- Mean Absolute Error (MAE)\n",
    "\n",
    "to quantify the overall accuracy of the geocoding results. <br>\n",
    "\n",
    "\n",
    "![MSE](../figs/lab5_figs/MSE.png)\n",
    "![RMSE](../figs/lab5_figs/RMSE.jpg)\n",
    "\n",
    "![MAE](../figs/lab5_figs/MAE.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847009b6-a780-440d-afc1-34fbd47cd771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, asin, sqrt\n",
    "import numpy as np\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    return 2 * 6371 * asin(sqrt(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b5384-b01e-4f10-a28d-d3bb5c0a4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_dist_off(df, col):\n",
    "    dist_off = []\n",
    "    for _,r in df.iterrows():\n",
    "        if r[col] != None:\n",
    "            dist_off.append(haversine(r['lon'],r['lat'], r[col][1], r[col][0]))\n",
    "    return np.mean(dist_off)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214324cd",
   "metadata": {},
   "source": [
    "**Compute the mean distance off for the two geocoders:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534741b2-c023-46b0-b818-56ec5a554ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "arcgis_mean_dist_off = mean_dist_off(df,'LAT_LON_arcgis')\n",
    "arcgis_mean_dist_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad648b38-4a4c-4ff3-bc03-279754746734",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_mean_dist_off = mean_dist_off(df,'LAT_LON_osm')\n",
    "osm_mean_dist_off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dd8690",
   "metadata": {},
   "source": [
    "**Compute the recall for the two geocoders:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78666015-ee16-477a-afcf-7d1f96d9bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_arcgis = len(df['LAT_LON_arcgis'].dropna())/len(df['name'])\n",
    "recall_arcgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12eb67f-61ad-47d8-8726-225ed9d548eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_osm = len(df['LAT_LON_osm'].dropna())/len(df['name'])\n",
    "recall_osm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d593c2",
   "metadata": {},
   "source": [
    "### 2.3 - Visual Inspection\n",
    "Plot the geocoding results on a map and visually inspect the locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0557d9cf-a8f3-4f65-bfdd-66dc6f97687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# add the first point as the start location and adjust the zoom level\n",
    "cafe_map = folium.Map(location=(df['lat'][0], df['lon'][0]), zoom_start=13, tiles=\"OpenStreetMap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee5359-93d2-4dfb-b152-15b8f4eb0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ground truth as a feature group\n",
    "feature_group_gt = folium.FeatureGroup(\"Ground Truth\")\n",
    "for _, r in df.iterrows():\n",
    "    popup = folium.Popup(r['name'])\n",
    "    feature_group_gt.add_child(folium.Marker(location=[r['lat'], r['lon']], icon=folium.Icon(color='red'), popup=popup))\n",
    "    \n",
    "# add arcgis results as a feature group\n",
    "feature_group_arcgis = folium.FeatureGroup(\"ArcGIS Results\")\n",
    "for _, r in df.iterrows():\n",
    "    popup = folium.Popup(r['name'])\n",
    "    if r['LAT_LON_arcgis'] != None:\n",
    "        feature_group_arcgis.add_child(folium.Marker(location=[r['LAT_LON_arcgis'][0], r['LAT_LON_arcgis'][1]],\n",
    "                                                     icon=folium.Icon(color='blue'), popup=popup))\n",
    "    \n",
    "# add OpenStreetMap results as a feature group\n",
    "feature_group_osm = folium.FeatureGroup(\"OSM Results\")\n",
    "for _, r in df.iterrows():\n",
    "    popup = folium.Popup(r['name'])\n",
    "    if r['LAT_LON_osm'] != None:\n",
    "        feature_group_osm.add_child(folium.Marker(location=[r['LAT_LON_osm'][0], r['LAT_LON_osm'][1]],\n",
    "                                                 icon=folium.Icon(color='green'), popup=popup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4fb0ea-2495-4600-885b-cf0a04d123d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add all feature groups to the map\n",
    "cafe_map.add_child(feature_group_gt)\n",
    "cafe_map.add_child(feature_group_arcgis)\n",
    "cafe_map.add_child(feature_group_osm)\n",
    "                                   \n",
    "## add layer control to the map\n",
    "folium.LayerControl().add_to(cafe_map)\n",
    "cafe_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8030ac7",
   "metadata": {},
   "source": [
    "![map](../figs/lab5_figs/map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefd0112",
   "metadata": {},
   "source": [
    "### 2.4 - Your observation based on the mean_dist_off, recall, and visual inspection:\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4a57ba-335f-4458-8c2b-3de2a7d28e43",
   "metadata": {
    "id": "ec4a57ba-335f-4458-8c2b-3de2a7d28e43"
   },
   "source": [
    "## 3 - Submission\n",
    "Try the code blocks above, complete section 2.4 and submit the .ipynb file on Moodle."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
>>>>>>> 444a0eec4505859ac59db5a7830d198c1a05cf9a
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.12.0"
=======
   "version": "3.12.2"
>>>>>>> 444a0eec4505859ac59db5a7830d198c1a05cf9a
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
